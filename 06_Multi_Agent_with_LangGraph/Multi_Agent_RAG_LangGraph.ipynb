{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxpWDFG11o3G"
   },
   "source": [
    "# Multi-Agent Workflows + RAG - LangGraph\n",
    "\n",
    "Today we'll be looking at an example of a Multi-Agent workflow that's powered by LangGraph, LCEL, and more!\n",
    "\n",
    "We're going to be, more specifically, looking at a \"heirarchical agent teams\" from the [AutoGen: Enabling Next-Gen LLM\n",
    "Applications via Multi-Agent Conversation](https://arxiv.org/pdf/2308.08155) paper.\n",
    "\n",
    "This will be the final \"graph\" of our system:\n",
    "\n",
    "![image](https://i.imgur.com/r5LMMCt.png)\n",
    "\n",
    "It's important to keep in mind that the actual implementation will be constructed of 3 separate graphs, the final one having 2 graphs as nodes! LangGraph is a heckuva tool!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyzoBrWoYeOZ"
   },
   "source": [
    "# ðŸ¤ BREAKOUT ROOM #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mx3oaVoX5cA2"
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zpv2MWqu5vS9"
   },
   "source": [
    "Since we'll be relying on OpenAI's suite of models to power our agents today, we'll want to provide our OpenAI API Key.\n",
    "\n",
    "We're also going to be using the Tavily search tool - so we'll want to provide that API key as well!\n",
    "\n",
    "Instruction for how to obtain the Tavily API key can be found:\n",
    "\n",
    "1. [Tavily API Key](https://app.tavily.com/sign-in)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h30OjkLfeR2Y",
    "outputId": "f75bb26e-b89d-4611-c29b-f339b3e868af"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_LD7rwT6PbO"
   },
   "source": [
    "## Task 1: Simple LangGraph RAG\n",
    "\n",
    "Now that we have our dependencies set-up - let's create a simple RAG graph that works over our AI Usage Data from previous sessions.\n",
    "\n",
    "> NOTE: While this particular example is very straight forward - you can \"plug in\" any complexity of chain you desire as a node in a LangGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JY7T5kxJ6jGn"
   },
   "source": [
    "## Retrieval\n",
    "\n",
    "The 'R' in 'RAG' - this is, at this point, fairly straightforward!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGuPxSCk7Ztz"
   },
   "source": [
    "#### Data Collection and Processing\n",
    "\n",
    "A classic first step, at this point, let's grab our desired document!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LfuoEYRCln3H"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "directory_loader = DirectoryLoader(\"data\", glob=\"**/*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "\n",
    "how_people_use_ai_documents = directory_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_t_F1zG6vXa"
   },
   "source": [
    "Now we can chunk it down to size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5R7A_z8CgL79"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    tokens = tiktoken.encoding_for_model(\"gpt-4o\").encode(\n",
    "        text,\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 750,\n",
    "    chunk_overlap = 0,\n",
    "    length_function = tiktoken_len,\n",
    ")\n",
    "\n",
    "how_people_use_ai_chunks = text_splitter.split_documents(how_people_use_ai_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGE-VuMc7AKv"
   },
   "source": [
    "Now we've successfully split our single PDF into..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pgYBHsdWmLvW",
    "outputId": "aa9a830e-f7db-4bb3-f542-c0614cb01aca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(how_people_use_ai_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGWs7KTd7QPS"
   },
   "source": [
    "#### Embedding Model and Vector Store\n",
    "\n",
    "Now that we have our chunked document - lets create a vector store, which will first require us to create an embedding model to get the vector representations of our text!\n",
    "\n",
    "We'll use OpenAI's [`text-embedding-3-small`](https://platform.openai.com/docs/guides/embeddings/embedding-models) model - as it's cheap, and performant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xLIWMMZCmfrj"
   },
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTEi7Ww573sc"
   },
   "source": [
    "Now we can create our QDrant backed vector store!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Xct51f8omVAU"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "qdrant_vectorstore = Qdrant.from_documents(\n",
    "    documents=how_people_use_ai_chunks,\n",
    "    embedding=embedding_model,\n",
    "    location=\":memory:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzGq6o4s79Ar"
   },
   "source": [
    "Let's make sure we can access it as a retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OTnQZbWymi4K"
   },
   "outputs": [],
   "source": [
    "qdrant_retriever = qdrant_vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aU8qSrMS7_D7"
   },
   "source": [
    "### Augmented\n",
    "\n",
    "Now that we have our retrieval process set-up, we need to set up our \"augmentation\" process - AKA a prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lezTN0zCmk46"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "HUMAN_TEMPLATE = \"\"\"\n",
    "#CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUERY:\n",
    "{query}\n",
    "\n",
    "Use the provide context to answer the provided user query. Only use the provided context to answer the query. If you do not know the answer, or it's not contained in the provided context respond with \"I don't know\"\n",
    "\"\"\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", HUMAN_TEMPLATE)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9fa63nM7IKK"
   },
   "source": [
    "### Generation\n",
    "\n",
    "Last, but certainly not least, let's put the 'G' in 'RAG' by adding our generator - in this case, we can rely on OpenAI's [`gpt-4o-mini`](https://platform.openai.com/docs/models/gpt-4o-mini) model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AwEi29-Jo3a8"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "generator_llm = ChatOpenAI(model=\"gpt-4.1-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qO-ZC0T98XJJ"
   },
   "source": [
    "### RAG - Retrieval Augmented Generation\n",
    "\n",
    "All that's left to do is combine our R, A, and G into a single graph - and we're off!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nlOJrPm_oT3S"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "class State(TypedDict):\n",
    "  question: str\n",
    "  context: List[Document]\n",
    "  response: str\n",
    "\n",
    "def retrieve(state: State):\n",
    "  retrieved_docs = qdrant_retriever.invoke(state[\"question\"])\n",
    "  return {\"context\" : retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "  generator_chain = chat_prompt | generator_llm | StrOutputParser()\n",
    "  response = generator_chain.invoke({\"query\" : state[\"question\"], \"context\" : state[\"context\"]})\n",
    "  return {\"response\" : response}\n",
    "\n",
    "rag_graph = StateGraph(State).add_sequence([retrieve, generate])\n",
    "rag_graph.add_edge(START, \"retrieve\")\n",
    "compiled_rag_graph = rag_graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qiWrbXpu8ggz"
   },
   "source": [
    "Let's test this out and make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "gJhFlW32pBPe",
    "outputId": "7aee04b6-608f-4639-adca-66225d4d3002"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How does the average person use AI?',\n",
       " 'context': [Document(metadata={'producer': 'macOS Version 15.4.1 (Build 24E263) Quartz PDFContext, AppendMode 1.1', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-12T20:05:32+00:00', 'source': 'data/howpeopleuseai.pdf', 'file_path': 'data/howpeopleuseai.pdf', 'total_pages': 64, 'format': 'PDF 1.6', 'title': 'How People Use ChatGPT', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-15T10:32:36-04:00', 'trapped': '', 'modDate': \"D:20250915103236-04'00'\", 'creationDate': 'D:20250912200532Z', 'page': 17, '_id': '8ca2bbcc2f4d413092c7ce5a328d6f75', '_collection_name': 'df96dc77801047c39f983060c08f7134'}, page_content='suggests that most user Writing conversations with ChatGPT are requests to modify user inputs\\nrather than to create something new. Education is a major use case for ChatGPT. 10.2% of all user\\nmessages and 36% of Practical Guidance messages are requests for Tutoring or Teaching. Another\\nlarge share - 8.5% in total and 30% of Practical Guidance - is general how-to advice on a variety\\nof topics. Technical Help includes Computer Programming (4.2% of messages), Mathematical Calcu-\\nlations (3%), and Data Analysis (0.4%). Looking at the topic of Self-Expression, only 2.4% of all\\nChatGPT messages are about Relationships and Personal Reflection (1.9%) or Games and Role Play\\n(0.4%).\\nWhile users can seek information and advice from traditional web search engines as well as from\\nChatGPT, the ability to produce writing, software code, spreadsheets, and other digital products\\ndistinguishes generative AI from existing technologies.\\nChatGPT is also more flexible than web\\nsearch even for traditional applications like Seeking Information and Practical Guidance, because\\nusers receive customized responses (e.g., tailored workout plans, new product ideas, ideas for fantasy\\nfootball team names) that represent newly generated content or novel modification of user-provided\\ncontent and follow-up requests.\\nFigure 9: Breakdown of granular conversation topic shares within the coarse mapping defined in Table 3. The\\nunderlying classifier prompt is available in Appendix A. Each bin reports a percentage of the total population.\\nShares are calculated from a sample of approximately 1.1 million sampled conversations from May 15, 2024\\nthrough June 26, 2025. Observations are reweighted to reflect total message volumes on a given day. Sampling\\ndetails available in Section 3.\\n5.3\\nUser Intent\\nExisting studies of the economic impacts of generative AI focus almost exclusively on the potential\\nfor AI to perform workplace tasks, either augmenting or automating human labor (e.g. Eloundou et\\nal. (2025), Handa et al. (2025), Tomlinson et al. (2025)). However, generative AI is a highly flexible\\n16'),\n",
       "  Document(metadata={'producer': 'macOS Version 15.4.1 (Build 24E263) Quartz PDFContext, AppendMode 1.1', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-12T20:05:32+00:00', 'source': 'data/howpeopleuseai.pdf', 'file_path': 'data/howpeopleuseai.pdf', 'total_pages': 64, 'format': 'PDF 1.6', 'title': 'How People Use ChatGPT', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-15T10:32:36-04:00', 'trapped': '', 'modDate': \"D:20250915103236-04'00'\", 'creationDate': 'D:20250912200532Z', 'page': 4, '_id': 'a5fff3f28547468a8a3c893284a2a0ca', '_collection_name': 'df96dc77801047c39f983060c08f7134'}, page_content='to Games and Role Play. In contrast, Zao-Sanders (2025) estimates that Therapy/Companionship is\\nthe most prevalent use case for generative AI.9\\nWe also document several important facts about demographic variation in ChatGPT usage. First,\\nwe show evidence that the gender gap in ChatGPT usage has likely narrowed considerably over time,\\nand may have closed completely. In the few months after ChatGPT was released about 80% of active\\nusers had typically masculine first names.10 However, that number declined to 48% as of June 2025,\\nwith active users slightly more likely to have typically feminine first names. Second, we find that\\nnearly half of all messages sent by adults were sent by users under the age of 26, although age gaps\\nhave narrowed somewhat in recent months. Third, we find that ChatGPT usage has grown relatively\\nfaster in low- and middle-income countries over the last year. Fourth, we find that educated users and\\nusers in highly-paid professional occupations are substantially more likely to use ChatGPT for work.\\nWe introduce a new taxonomy to classify messages according to the kind of output the user is\\nseeking, using a simple rubric that we call Asking, Doing, or Expressing.11\\nAsking is when the\\nuser is seeking information or clarification to inform a decision, corresponding to problem-solving\\nmodels of knowledge work (e.g., Garicano (2000); Garicano and Rossi-Hansberg (2006); Carnehl and\\nSchneider (2025); Ide and Talamas (2025)). Doing is when the user wants to produce some output\\nor perform a particular task, corresponding to classic task-based models of work (e.g., Autor et al.\\n(2003)). Expressing is when the user is expressing views or feelings but not seeking any information or\\naction. We estimate that about 49% of messages are Asking, 40% are Doing, and 11% are Expressing.\\nHowever, as of July 2025 about 56% of work-related messages are classified as Doing (e.g., performing\\njob tasks), and nearly three-quarters of those are Writing tasks. The relative frequency of writing-\\nrelated conversations is notable for two reasons. First, writing is a task that is common to nearly all\\nwhite-collar jobs, and good written communication skills are among the top â€œsoftâ€ skills demanded by\\nemployers (National Association of Colleges and Employers, 2024). Second, one distinctive feature of\\ngenerative AI, relative to other information technologies, is its ability to produce long-form outputs\\nsuch as writing and software code.\\nWe also map message content to work activities using the Occupational Information Network\\n(O*NET), a survey of job characteristics supported by the U.S. Department of Labor. We find that\\nabout 81% of work-related messages are associated with two broad work activities: 1) obtaining,\\ndocumenting, and interpreting information; and 2) making decisions, giving advice, solving problems,\\nand thinking creatively. Additionally, we find that the work activities associated with ChatGPT usage\\nare highly similar across very different kinds of occupations. For example, the work activities Getting\\nInformation and Making Decisions and Solving Problems are in the top five of message frequency in\\nnearly all occupations, ranging from management and business to STEM to administrative and sales\\noccupations.\\nOverall, we find that information-seeking and decision support are the most common ChatGPT\\nuse cases in most jobs. This is consistent with the fact that almost half of all ChatGPT usage is'),\n",
       "  Document(metadata={'producer': 'macOS Version 15.4.1 (Build 24E263) Quartz PDFContext, AppendMode 1.1', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-12T20:05:32+00:00', 'source': 'data/howpeopleuseai.pdf', 'file_path': 'data/howpeopleuseai.pdf', 'total_pages': 64, 'format': 'PDF 1.6', 'title': 'How People Use ChatGPT', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-15T10:32:36-04:00', 'trapped': '', 'modDate': \"D:20250915103236-04'00'\", 'creationDate': 'D:20250912200532Z', 'page': 43, '_id': '1d1dc6bc75414fe4be0a846174c0e1a9', '_collection_name': 'df96dc77801047c39f983060c08f7134'}, page_content='A.3\\nConversation Topic\\n-----\\nYou are an internal tool that classifies a message from a user to an AI chatbot,\\nbased on the context of the previous messages before it.\\n,â†’\\nBased on the last user message of this conversation transcript and taking into\\naccount the examples further below as guidance, please select the capability\\nthe user is clearly interested in, or `other` if it is clear but not in the\\nlist below, or `unclear` if it is hard to tell what the user even wants:\\n,â†’\\n,â†’\\n,â†’\\n- **edit_or_critique_provided_text**: Improving or modifying text provided by the\\nuser.\\n,â†’\\n- **argument_or_summary_generation**: Creating arguments or summaries on topics not\\nprovided in detail by the user.\\n,â†’\\n- **personal_writing_or_communication**: Assisting with personal messages, emails,\\nor social media posts.\\n,â†’\\n- **write_fiction**: Crafting poems, stories, or fictional content.\\n- **how_to_advice**: Providing step-by-step instructions or guidance on how to\\nperform tasks or learn new skills.\\n,â†’\\n- **creative_ideation**: Generating ideas or suggestions for creative projects or\\nactivities.\\n,â†’\\n- **tutoring_or_teaching**: Explaining concepts, teaching subjects, or helping the\\nuser understand educational material.\\n,â†’\\n- **translation**: Translating text from one language to another.\\n- **mathematical_calculation**: Solving math problems, performing calculations, or\\nworking with numerical data.\\n,â†’\\n- **computer_programming**: Writing code, debugging, explaining programming\\nconcepts, or discussing programming languages and tools.\\n,â†’\\n- **purchasable_products**: Inquiries about products or services available for\\npurchase.\\n,â†’\\n42'),\n",
       "  Document(metadata={'producer': 'macOS Version 15.4.1 (Build 24E263) Quartz PDFContext, AppendMode 1.1', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-09-12T20:05:32+00:00', 'source': 'data/howpeopleuseai.pdf', 'file_path': 'data/howpeopleuseai.pdf', 'total_pages': 64, 'format': 'PDF 1.6', 'title': 'How People Use ChatGPT', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-09-15T10:32:36-04:00', 'trapped': '', 'modDate': \"D:20250915103236-04'00'\", 'creationDate': 'D:20250912200532Z', 'page': 41, '_id': '88ac968c05e64b72b399a1096ad5e2b3', '_collection_name': 'df96dc77801047c39f983060c08f7134'}, page_content='Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N.\\nGomez, Lukasz Kaiser, and Illia Polosukhin, â€œAttention Is All You Need,â€ in I. Guyon,\\nU. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, eds., Ad-\\nvances in Neural Information Processing Systems, Vol. 30 of 31st Conference on Neural Information\\nProcessing Systems (NIPS) Curran Associates, Inc. Long Beach, CA, USA 2017.\\nWest, Jevin D., Jennifer Jacquet, Molly M. King, Shelley J. Correll, and Carl T.\\nBergstrom, â€œThe Role of Gender in Scholarly Authorship,â€ PLoS ONE, 2013, 8 (7), e66212.\\nWiggers, Kyle, â€œChatGPT Isnâ€™t the Only Chatbot Thatâ€™s Gaining Users,â€ TechCrunch, 2025. Ac-\\ncessed: 2025-09-10.\\nZao-Sanders, Marc, â€œHow People Are Really Using Gen AI in 2025,â€ Harvard Business Review\\nApril 2025. https://hbr.org/2025/04/how-people-are-really-using-gen-ai-in-2025.\\nZhao, Wenting, Xiang Ren, Jack Hessel, Claire Cardie, Yejin Choi, and Yuntian Deng,\\nâ€œWildChat: 1M ChatGPT Interaction Logs in the Wild,â€ 2024.\\n40')],\n",
       " 'response': 'The average person uses AI primarily for communication, information-seeking, and practical guidance. Most user interactions involve requests to modify or improve user-provided content rather than creating entirely new material. Education is a significant use case, with many messages about tutoring, teaching, or general how-to advice on various topics. Users also seek technical help related to programming, mathematics, or data analysis. Additionally, a notable portion of conversations involve self-expression, such as relationships, personal reflection, games, and role play. Generative AI is valued for its ability to produce long-form outputs like writing and software code, enabling customized responses and supporting tasks across many domains.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_rag_graph.invoke({\"question\" : \"How does the average person use AI?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gReMizYk8qd-"
   },
   "source": [
    "### RAG Limitation\n",
    "\n",
    "Notice how we're hard-coding our data, while this is simply meant to be an illustrative example - you could easily extend this to work with any provied paper or document in order to have a more dynamic system.\n",
    "\n",
    "For now, we'll stick with this single hard-coded example in order to keep complexity down in an already very long notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxkbuir-H5rE"
   },
   "source": [
    "##### ðŸ—ï¸ Activity #1 (Bonus Marks)\n",
    "\n",
    "Allow the system to dynamically fetch Arxiv papers instead of hard coding them.\n",
    "\n",
    "> HINT: Tuesday's assignment will be very useful here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7U6a_pqQ9uWf"
   },
   "source": [
    "## Task 2: Helper Functions for Agent Graphs\n",
    "\n",
    "We'll be using a number of agents, nodes, and supervisors in the rest of the notebook - and so it will help to have a collection of useful helper functions that we can leverage to make our lives easier going forward.\n",
    "\n",
    "Let's start with the most simple one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDUnpEEl-L_F"
   },
   "source": [
    "#### Import Wall\n",
    "\n",
    "Here's a wall of imports we'll be needing going forward!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbzoL3Q3-SG1"
   },
   "outputs": [],
   "source": [
    "from typing import Any, Callable, List, Optional, TypedDict, Union\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb6Z3EEz-Asi"
   },
   "source": [
    "### Agent Node Helper\n",
    "\n",
    "Since we're going to be wrapping each of our agents into a node - it will help to have an easy way to create the node!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5IF7KWfS-JKd"
   },
   "outputs": [],
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwND2teK-WHm"
   },
   "source": [
    "### Agent Creation Helper Function\n",
    "\n",
    "Since we know we'll need to create agents to populate our agent nodes, let's use a helper function for that as well!\n",
    "\n",
    "Notice a few things:\n",
    "\n",
    "1. We have a standard suffix to append to our system messages for each agent to handle the tool calling and boilerplate prompting.\n",
    "2. Each agent has its our scratchpad.\n",
    "3. We're relying on OpenAI's function-calling API for tool selection\n",
    "4. Each agent is its own executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NxLyHJt5-eUx"
   },
   "outputs": [],
   "source": [
    "def create_agent(\n",
    "    llm: ChatOpenAI,\n",
    "    tools: list,\n",
    "    system_prompt: str,\n",
    ") -> str:\n",
    "    \"\"\"Create a function-calling agent and add it to the graph.\"\"\"\n",
    "    system_prompt += (\"\\nWork autonomously according to your specialty, using the tools available to you.\"\n",
    "    \" Do not ask for clarification.\"\n",
    "    \" Your other team members (and other teams) will collaborate with you with their own specialties.\"\n",
    "    \" You are chosen for a reason!\")\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6kmlR9d-1K5"
   },
   "source": [
    "### Supervisor Helper Function\n",
    "\n",
    "Finally, we need a \"supervisor\" that decides and routes tasks to specific agents.\n",
    "\n",
    "Since each \"team\" will have a collection of potential agents - this \"supervisor\" will act as an \"intelligent\" router to make sure that the right agent is selected for the right task.\n",
    "\n",
    "Notice that, at the end of the day, this \"supervisor\" is simply directing who acts next - or if the state is considered \"done\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "S2MXA83mrYE2"
   },
   "outputs": [],
   "source": [
    "def create_team_supervisor(llm: ChatOpenAI, system_prompt, members) -> str:\n",
    "    \"\"\"An LLM-based router.\"\"\"\n",
    "    options = [\"FINISH\"] + members\n",
    "    function_def = {\n",
    "        \"name\": \"route\",\n",
    "        \"description\": \"Select the next role.\",\n",
    "        \"parameters\": {\n",
    "            \"title\": \"routeSchema\",\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"next\": {\n",
    "                    \"title\": \"Next\",\n",
    "                    \"anyOf\": [\n",
    "                        {\"enum\": options},\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"next\"],\n",
    "        },\n",
    "    }\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\n",
    "                \"system\",\n",
    "                \"Given the conversation above, who should act next?\"\n",
    "                \" Or should we FINISH? Select one of: {options}\",\n",
    "            ),\n",
    "        ]\n",
    "    ).partial(options=str(options), team_members=\", \".join(members))\n",
    "    return (\n",
    "        prompt\n",
    "        | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "        | JsonOutputFunctionsParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jd0zfyq48jKb"
   },
   "source": [
    "## Task 3: Research Team - A LangGraph for Researching AI Usage Policy\n",
    "\n",
    "Now that we have our RAG chain set-up and some awesome helper functions, we want to create a LangGraph related to researching a specific topic, in this case: How People Use AI!\n",
    "\n",
    "We're going to start by equipping our Research Team with a few tools:\n",
    "\n",
    "1. Tavily Search - aka \"Google\", for the most up to date information possible.\n",
    "2. Our RAG chain - specific and high quality information about our topic.\n",
    "\n",
    "Let's create those tools now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNsVTZrH_alw"
   },
   "source": [
    "### Tool Creation\n",
    "\n",
    "As you can see below, some tools already come pre-packaged ready to use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ce7FKTZDgAWG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mx/qvv_bb753pbddmt0mg2mpskc0000gn/T/ipykernel_83856/1911882425.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_tool = TavilySearchResults(max_results=5)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIR7cbTL9agM"
   },
   "source": [
    "Creating a custom tool, however, is very straightforward.\n",
    "\n",
    "> NOTE: You *must* include a docstring, as that is what the LLM will consider when deciding when to use this tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "sSwO2L_UqFhm"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Tuple, Union\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def retrieve_information(\n",
    "    query: Annotated[str, \"query to ask the retrieve information tool\"]\n",
    "    ):\n",
    "  \"\"\"Use Retrieval Augmented Generation to retrieve information about how people use AI\"\"\"\n",
    "  return compiled_rag_graph.invoke({\"question\" : query})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxsMnqjpBTCj"
   },
   "source": [
    "> NOTE: We could just as easily use the LCEL chain directly, since nodes can be LCEL objects - but creating a tool helps explain the tool creation process at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDHCajO4_gB2"
   },
   "source": [
    "### Research Team State\n",
    "\n",
    "Since we're using LangGraph - we're going to need state!\n",
    "\n",
    "Let's look at how we've created our state below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "mXminK9d_1fa"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "import functools\n",
    "\n",
    "class ResearchTeamState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    team_members: List[str]\n",
    "    next: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvPM5msq_18C"
   },
   "source": [
    "Notice how we've used `messages`, `team_members`, and `next`.\n",
    "\n",
    "These states will help us understand:\n",
    "\n",
    "1. What we've done so far (`messages`)\n",
    "2. Which team members we have access to (`team_members`)\n",
    "3. Which team member is up next! (`next`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mu7B_6qHAFjK"
   },
   "source": [
    "### Research Team LLM\n",
    "\n",
    "We'll be using `gpt-4o-mini` today. This LLM is going to be doing a lot of reasoning - but we also want to keep our costs down, so we'll use a lightweight; but powerful, model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "dTNqrip8AcKR"
   },
   "outputs": [],
   "source": [
    "research_llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfb_VCNKIy9w"
   },
   "source": [
    "##### â“ Question #1:\n",
    "\n",
    "Why is a \"powerful\" LLM important for this use-case?\n",
    "\n",
    "What tasks must our Agent perform that make it such that the LLM's reasoning capability is a potential limiter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR_1LuMKAekf"
   },
   "source": [
    "### Research Team Agents & Nodes\n",
    "\n",
    "Now we can use our helper functions to create our agent nodes, with their related tools.\n",
    "\n",
    "Let's start with our search agent node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzx6wuPoAlPq"
   },
   "source": [
    "#### Research Team: Search Agent\n",
    "\n",
    "We're going to give our agent access to the Tavily tool, power it with our GPT-4o Mini model, and then create its node - and name it `Search`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FIlLPxj7Atpj"
   },
   "outputs": [],
   "source": [
    "search_agent = create_agent(\n",
    "    research_llm,\n",
    "    [tavily_tool],\n",
    "    \"You are a research assistant who can search for up-to-date info using the tavily search engine.\",\n",
    ")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emLtesudA9Dd"
   },
   "source": [
    "#### Research Team: RAG Agent Node\n",
    "\n",
    "Now we can wrap our LCEL RAG pipeline in an agent node as well, using the LCEL RAG pipeline as the tool, as created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "z-nnAG9XA_p7"
   },
   "outputs": [],
   "source": [
    "research_agent = create_agent(\n",
    "    research_llm,\n",
    "    [retrieve_information],\n",
    "    \"You are a research assistant who can provide specific information on how people use AI\",\n",
    ")\n",
    "research_node = functools.partial(agent_node, agent=research_agent, name=\"HowPeopleUseAIRetriever\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dA5z6T1CBeSc"
   },
   "source": [
    "### Research Team Supervisor Agent\n",
    "\n",
    "Notice that we're not yet creating our supervisor *node*, simply the agent here.\n",
    "\n",
    "Also notice how we need to provide a few extra pieces of information - including which tools we're using.\n",
    "\n",
    "> NOTE: It's important to use the *exact* tool name, as that is how the LLM will reference the tool. Also, it's important that your tool name is all a single alphanumeric string!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "J0g8CQMBrtFs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mx/qvv_bb753pbddmt0mg2mpskc0000gn/T/ipykernel_83856/488856706.py:34: LangChainDeprecationWarning: The method `BaseChatOpenAI.bind_functions` was deprecated in langchain-openai 0.2.1 and will be removed in 1.0.0. Use :meth:`~langchain_openai.chat_models.base.ChatOpenAI.bind_tools` instead.\n",
      "  | llm.bind_functions(functions=[function_def], function_call=\"route\")\n"
     ]
    }
   ],
   "source": [
    "research_supervisor_agent = create_team_supervisor(\n",
    "    research_llm,\n",
    "    (\"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  Search, HowPeopleUseAIRetriever. Given the following user request,\"\n",
    "    \" determine the subject to be researched and respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. \"\n",
    "    \" You should never ask your team to do anything beyond research. They are not required to write content or posts.\"\n",
    "    \" You should only pass tasks to workers that are specifically research focused.\"\n",
    "    \" When finished, respond with FINISH.\"),\n",
    "    [\"Search\", \"HowPeopleUseAIRetriever\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qohn0DcgB_U1"
   },
   "source": [
    "### Research Team Graph Creation\n",
    "\n",
    "Now that we have our research team agent nodes created, and our supervisor agent - let's finally construct our graph!\n",
    "\n",
    "We'll start by creating our base graph from our state, and then adding the nodes/agent we've created as nodes on our LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "p0s2GAgJCN8G"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1606647d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_graph = StateGraph(ResearchTeamState)\n",
    "\n",
    "research_graph.add_node(\"Search\", search_node)\n",
    "research_graph.add_node(\"HowPeopleUseAIRetriever\", research_node)\n",
    "research_graph.add_node(\"ResearchSupervisor\", research_supervisor_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33qixRGNCaAX"
   },
   "source": [
    "Now we can define our edges - include our conditional edge from our supervisor to our agent nodes.\n",
    "\n",
    "Notice how we're always routing our agent nodes back to our supervisor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "yYSJIhijsGyg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1606647d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_graph.add_edge(\"Search\", \"ResearchSupervisor\") \n",
    "research_graph.add_edge(\"HowPeopleUseAIRetriever\", \"ResearchSupervisor\")\n",
    "research_graph.add_conditional_edges(\n",
    "    \"ResearchSupervisor\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\"Search\": \"Search\", \"HowPeopleUseAIRetriever\": \"HowPeopleUseAIRetriever\", \"FINISH\": END},\n",
    ")\n",
    "research_graph.set_entry_point(\"ResearchSupervisor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgGcuZzkCj1-"
   },
   "source": [
    "Now we can set our supervisor node as the entry point, and compile our graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1l-1I2Z3CnPX"
   },
   "outputs": [],
   "source": [
    "compiled_research_graph = research_graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDwQpYTSEY13"
   },
   "source": [
    "#### Display Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph after 1 retries. To resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mgaierror\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/urllib3/connection.py:174\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     conn = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_kw\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/urllib3/util/connection.py:72\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m six.raise_from(\n\u001b[32m     69\u001b[39m         LocationParseError(\u001b[33mu\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, label empty or too long\u001b[39m\u001b[33m\"\u001b[39m % host), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     70\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     73\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.6-macos-aarch64-none/lib/python3.13/socket.py:977\u001b[39m, in \u001b[36mgetaddrinfo\u001b[39m\u001b[34m(host, port, family, type, proto, flags)\u001b[39m\n\u001b[32m    976\u001b[39m addrlist = []\n\u001b[32m--> \u001b[39m\u001b[32m977\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    978\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[31mgaierror\u001b[39m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNewConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:716\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[39m\n\u001b[32m    715\u001b[39m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m httplib_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[32m    728\u001b[39m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[32m    729\u001b[39m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:404\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[39m\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    406\u001b[39m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:1061\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1060\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[33m\"\u001b[39m\u001b[33msock\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1061\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/urllib3/connection.py:363\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    362\u001b[39m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = conn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     hostname = \u001b[38;5;28mself\u001b[39m.host\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/urllib3/connection.py:186\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[32m    187\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % e\n\u001b[32m    188\u001b[39m     )\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[31mNewConnectionError\u001b[39m: <urllib3.connection.HTTPSConnection object at 0x162616990>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:802\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[39m\n\u001b[32m    800\u001b[39m     e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, e)\n\u001b[32m--> \u001b[39m\u001b[32m802\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    805\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/urllib3/util/retry.py:594\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_retry.is_exhausted():\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[32m    596\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPSConnectionPool(host='mermaid.ink', port=443): Max retries exceeded with url: /img/LS0tCmNvbmZpZzoKICBmbG93Y2hhcnQ6CiAgICBjdXJ2ZTogbGluZWFyCi0tLQpncmFwaCBURDsKCV9fc3RhcnRfXyhbPHA+X19zdGFydF9fPC9wPl0pOjo6Zmlyc3QKCVNlYXJjaChTZWFyY2gpCglIb3dQZW9wbGVVc2VBSVJldHJpZXZlcihIb3dQZW9wbGVVc2VBSVJldHJpZXZlcikKCVJlc2VhcmNoU3VwZXJ2aXNvcihSZXNlYXJjaFN1cGVydmlzb3IpCglfX2VuZF9fKFs8cD5fX2VuZF9fPC9wPl0pOjo6bGFzdAoJSG93UGVvcGxlVXNlQUlSZXRyaWV2ZXIgLS0+IFJlc2VhcmNoU3VwZXJ2aXNvcjsKCVJlc2VhcmNoU3VwZXJ2aXNvciAtLi0+IEhvd1Blb3BsZVVzZUFJUmV0cmlldmVyOwoJUmVzZWFyY2hTdXBlcnZpc29yIC0uLT4gU2VhcmNoOwoJUmVzZWFyY2hTdXBlcnZpc29yIC0uICZuYnNwO0ZJTklTSCZuYnNwOyAuLT4gX19lbmRfXzsKCVNlYXJjaCAtLT4gUmVzZWFyY2hTdXBlcnZpc29yOwoJX19zdGFydF9fIC0tPiBSZXNlYXJjaFN1cGVydmlzb3I7CgljbGFzc0RlZiBkZWZhdWx0IGZpbGw6I2YyZjBmZixsaW5lLWhlaWdodDoxLjIKCWNsYXNzRGVmIGZpcnN0IGZpbGwtb3BhY2l0eTowCgljbGFzc0RlZiBsYXN0IGZpbGw6I2JmYjZmYwo=?type=png&bgColor=!white (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x162616990>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/langchain_core/runnables/graph_mermaid.py:443\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status_code == requests.codes.ok:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/requests/adapters.py:677\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    675\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mConnectionError\u001b[39m: HTTPSConnectionPool(host='mermaid.ink', port=443): Max retries exceeded with url: /img/LS0tCmNvbmZpZzoKICBmbG93Y2hhcnQ6CiAgICBjdXJ2ZTogbGluZWFyCi0tLQpncmFwaCBURDsKCV9fc3RhcnRfXyhbPHA+X19zdGFydF9fPC9wPl0pOjo6Zmlyc3QKCVNlYXJjaChTZWFyY2gpCglIb3dQZW9wbGVVc2VBSVJldHJpZXZlcihIb3dQZW9wbGVVc2VBSVJldHJpZXZlcikKCVJlc2VhcmNoU3VwZXJ2aXNvcihSZXNlYXJjaFN1cGVydmlzb3IpCglfX2VuZF9fKFs8cD5fX2VuZF9fPC9wPl0pOjo6bGFzdAoJSG93UGVvcGxlVXNlQUlSZXRyaWV2ZXIgLS0+IFJlc2VhcmNoU3VwZXJ2aXNvcjsKCVJlc2VhcmNoU3VwZXJ2aXNvciAtLi0+IEhvd1Blb3BsZVVzZUFJUmV0cmlldmVyOwoJUmVzZWFyY2hTdXBlcnZpc29yIC0uLT4gU2VhcmNoOwoJUmVzZWFyY2hTdXBlcnZpc29yIC0uICZuYnNwO0ZJTklTSCZuYnNwOyAuLT4gX19lbmRfXzsKCVNlYXJjaCAtLT4gUmVzZWFyY2hTdXBlcnZpc29yOwoJX19zdGFydF9fIC0tPiBSZXNlYXJjaFN1cGVydmlzb3I7CgljbGFzc0RlZiBkZWZhdWx0IGZpbGw6I2YyZjBmZixsaW5lLWhlaWdodDoxLjIKCWNsYXNzRGVmIGZpcnN0IGZpbGwtb3BhY2l0eTowCgljbGFzc0RlZiBsYXN0IGZpbGw6I2JmYjZmYwo=?type=png&bgColor=!white (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x162616990>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/IPython/core/formatters.py:1036\u001b[39m, in \u001b[36mMimeBundleFormatter.__call__\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m   1033\u001b[39m     method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:758\u001b[39m, in \u001b[36mPregel._repr_mimebundle_\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_repr_mimebundle_\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    755\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Mime bundle used by Jupyter to display the graph\"\"\"\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    757\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtext/plain\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m),\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimage/png\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    759\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/langchain_core/runnables/graph.py:702\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[39m\n\u001b[32m    692\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: PLC0415\u001b[39;00m\n\u001b[32m    693\u001b[39m     draw_mermaid_png,\n\u001b[32m    694\u001b[39m )\n\u001b[32m    696\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    697\u001b[39m     curve_style=curve_style,\n\u001b[32m    698\u001b[39m     node_colors=node_colors,\n\u001b[32m    699\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    700\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    701\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m702\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/langchain_core/runnables/graph_mermaid.py:310\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[39m\n\u001b[32m    304\u001b[39m     img_bytes = asyncio.run(\n\u001b[32m    305\u001b[39m         _render_mermaid_using_pyppeteer(\n\u001b[32m    306\u001b[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[32m    307\u001b[39m         )\n\u001b[32m    308\u001b[39m     )\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     img_bytes = \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    318\u001b[39m     supported_methods = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([m.value \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI-Maker-Space-AIE8/06_Multi_Agent_with_LangGraph/.venv/lib/python3.13/site-packages/langchain_core/runnables/graph_mermaid.py:475\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[39m\n\u001b[32m    470\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    471\u001b[39m             msg = (\n\u001b[32m    472\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    473\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour graph after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m retries. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    474\u001b[39m             ) + error_msg_suffix\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    477\u001b[39m \u001b[38;5;66;03m# This should not be reached, but just in case\u001b[39;00m\n\u001b[32m    478\u001b[39m msg = (\n\u001b[32m    479\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    480\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour graph after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m retries. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    481\u001b[39m ) + error_msg_suffix\n",
      "\u001b[31mValueError\u001b[39m: Failed to reach https://mermaid.ink/ API while trying to render your graph after 1 retries. To resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph at 0x160664910>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_research_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfRvA2QfCqFL"
   },
   "source": [
    "The next part is key - since we need to \"wrap\" our LangGraph in order for it to be compatible in the following steps - let's create an LCEL chain out of it!\n",
    "\n",
    "This allows us to \"broadcast\" messages down to our Research Team LangGraph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "1G7hmEINCx3i"
   },
   "outputs": [],
   "source": [
    "def enter_research_chain(message: str):\n",
    "    results = {\n",
    "        \"messages\": [HumanMessage(content=message)],\n",
    "    }\n",
    "    return results\n",
    "\n",
    "research_chain = enter_research_chain | compiled_research_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGdoCdXWC7Pi"
   },
   "source": [
    "Now, finally, we can take it for a spin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIDpFIg2sRUl",
    "outputId": "bb3803d4-5b32-4b0a-c8a1-1a1917425812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResearchSupervisor': {'next': 'HowPeopleUseAIRetriever'}}\n",
      "---\n",
      "{'HowPeopleUseAIRetriever': {'messages': [HumanMessage(content=\"People are using AI, such as ChatGPT, to improve their lives in several ways:\\n\\n1. **Information and Advice**: Many users leverage AI to seek information and advice, which helps them make informed decisions and solve problems. This is particularly useful in various domains like personal finance, health, and general knowledge.\\n\\n2. **Productivity Tasks**: AI is used to perform tasks such as writing, software coding, spreadsheet creation, and developing digital products. This highlights AI's role in enhancing productivity and creativity in both personal and professional settings.\\n\\n3. **Education and Tutoring**: AI serves as a valuable tool in education, offering personalized guidance for tutoring and teaching. Users can receive tailored educational support, making learning more accessible and effective.\\n\\n4. **General How-To Advice**: AI provides users with practical guidance on a wide range of topics, helping them to learn new skills and complete tasks more efficiently.\\n\\n5. **Self-Expression**: Some individuals use AI for self-expression, engaging in activities related to relationships, personal reflections, games, and role play. This use showcases AI's role in fostering creativity and personal growth.\\n\\nThe flexibility of AI allows users to access customized responses, making it a versatile tool for improving knowledge, enhancing productivity, and facilitating personal activities.\", additional_kwargs={}, response_metadata={}, name='HowPeopleUseAIRetriever')]}}\n",
      "---\n",
      "{'ResearchSupervisor': {'next': 'FINISH'}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for s in research_chain.stream(\n",
    "    \"How are people using AI to improve their lives?\", {\"recursion_limit\": 100}\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHAgsbwIIhwj"
   },
   "source": [
    "##### ðŸ—ï¸ Activity #2:\n",
    "\n",
    "Using whatever drawing application you wish - please label the flow above on a diagram of your graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eH70eHGlJbq4"
   },
   "source": [
    "##### â“ Question #2:\n",
    "\n",
    "How could you make sure your Agent uses specific tools that you wish it to use? Are there any ways to concretely set a flow through tools?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iktcBorGXmAW"
   },
   "source": [
    "# ðŸ¤ BREAKOUT ROOM #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejsHCZZ2EmwM"
   },
   "source": [
    "## Task 4: Document Writing Team - A LangGraph for Planning, Writing, and Editing a Formal Research Resport.\n",
    "\n",
    "Let's run it all back, this time specifically creating tools, agent nodes, and a graph for Planning, Writing, and Editing a Formal Research Resport!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previous Cohort Use Case Data\n",
    "\n",
    "Let's add a retriever for [previous cohort use-case data](./data/AIE7_Projects_with_Domains.csv) here!\n",
    "\n",
    "This will allow our response writing team reference previous responses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data/AIE7_Projects_with_Domains.csv', 'row': 0}, page_content='Project Domain: Customer Support / Helpdesk\\nSecondary Domain (if any): Productivity Assistants')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "previous_cohort_loader = CSVLoader(\"data/AIE7_Projects_with_Domains.csv\", content_columns=[\"Project Domain\", \"Secondary Domain (if any)\"])\n",
    "previous_cohort = previous_cohort_loader.load()\n",
    "previous_cohort[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_previous_cohort_vectorstore = Qdrant.from_documents(\n",
    "    documents=previous_cohort,\n",
    "    embedding=embedding_model,\n",
    "    location=\":memory:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_previous_cohort_retriever = qdrant_previous_cohort_vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4awQtZ-oFUN-"
   },
   "source": [
    "### Tool Creation\n",
    "\n",
    "Let's create some tools that will help us understand, open, work with, and edit documents to our liking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ptXilgparOkq"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Dict, Optional\n",
    "from typing_extensions import TypedDict\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "os.makedirs('./content/data', exist_ok=True)\n",
    "\n",
    "def create_random_subdirectory():\n",
    "    random_id = str(uuid.uuid4())[:8]  # Use first 8 characters of a UUID\n",
    "    subdirectory_path = os.path.join('./content/data', random_id)\n",
    "    os.makedirs(subdirectory_path, exist_ok=True)\n",
    "    return subdirectory_path\n",
    "\n",
    "WORKING_DIRECTORY = Path(create_random_subdirectory())\n",
    "\n",
    "@tool\n",
    "def create_outline(\n",
    "    points: Annotated[List[str], \"List of main points or sections.\"],\n",
    "    file_name: Annotated[str, \"File path to save the outline.\"],\n",
    ") -> Annotated[str, \"Path of the saved outline file.\"]:\n",
    "    \"\"\"Create and save an outline.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        for i, point in enumerate(points):\n",
    "            file.write(f\"{i + 1}. {point}\\n\")\n",
    "    return f\"Outline saved to {file_name}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def read_document(\n",
    "    file_name: Annotated[str, \"File path to save the document.\"],\n",
    "    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
    "    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
    ") -> str:\n",
    "    \"\"\"Read the specified document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    if start is not None:\n",
    "        start = 0\n",
    "    return \"\\n\".join(lines[start:end])\n",
    "\n",
    "@tool\n",
    "def write_document(\n",
    "    content: Annotated[str, \"Text content to be written into the document.\"],\n",
    "    file_name: Annotated[str, \"File path to save the document.\"],\n",
    ") -> Annotated[str, \"Path of the saved document file.\"]:\n",
    "    \"\"\"Create and save a text document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.write(content)\n",
    "    return f\"Document saved to {file_name}\"\n",
    "\n",
    "### Previous Cohort Use Case Data\n",
    "@tool \n",
    "def reference_previous_responses(\n",
    "    query: Annotated[str, \"The query to search for in the previous responses.\"],\n",
    ") -> Annotated[str, \"The previous responses that match the query.\"]:\n",
    "    \"\"\"Search for previous responses that match the query.\"\"\"\n",
    "    return qdrant_previous_cohort_retriever.invoke(query)\n",
    "\n",
    "\n",
    "@tool\n",
    "def edit_document(\n",
    "    file_name: Annotated[str, \"Path of the document to be edited.\"],\n",
    "    inserts: Annotated[\n",
    "        Dict[int, str],\n",
    "        \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n",
    "    ] = {},\n",
    ") -> Annotated[str, \"Path of the edited document file.\"]:\n",
    "    \"\"\"Edit a document by inserting text at specific line numbers.\"\"\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sorted_inserts = sorted(inserts.items())\n",
    "\n",
    "    for line_number, text in sorted_inserts:\n",
    "        if 1 <= line_number <= len(lines) + 1:\n",
    "            lines.insert(line_number - 1, text + \"\\n\")\n",
    "        else:\n",
    "            return f\"Error: Line number {line_number} is out of range.\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    return f\"Document edited and saved to {file_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8yH1IAYK7nL"
   },
   "source": [
    "##### ðŸ—ï¸ Activity #3:\n",
    "\n",
    "Describe, briefly, what each of these tools is doing in your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__Jw_XBIFwwa"
   },
   "source": [
    "### Document Writing State\n",
    "\n",
    "Just like with our Research Team state - we want to keep track of a few things, however this time - we also want to keep track of which files we've created - so let's add that here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "DoU2YwJRu7wD"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from pathlib import Path\n",
    "\n",
    "class DocWritingState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    team_members: str\n",
    "    next: str\n",
    "    current_files: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4p1kQShmGHCh"
   },
   "source": [
    "### Document Writing Prelude Function\n",
    "\n",
    "Since we have a working directory - we want to be clear about what our current working directory looks like - this helper function will allow us to do that cleanly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "G79mUggQGLVq"
   },
   "outputs": [],
   "source": [
    "def prelude(state):\n",
    "    written_files = []\n",
    "    if not WORKING_DIRECTORY.exists():\n",
    "        WORKING_DIRECTORY.mkdir()\n",
    "    try:\n",
    "        written_files = [\n",
    "            f.relative_to(WORKING_DIRECTORY) for f in WORKING_DIRECTORY.rglob(\"*\")\n",
    "        ]\n",
    "    except:\n",
    "        pass\n",
    "    if not written_files:\n",
    "        return {**state, \"current_files\": \"No files written.\"}\n",
    "    return {\n",
    "        **state,\n",
    "        \"current_files\": \"\\nBelow are files your team has written to the directory:\\n\"\n",
    "        + \"\\n\".join([f\" - {f}\" for f in written_files]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbSre9agT9Gb"
   },
   "source": [
    "### Document Writing Node Creation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "authoring_llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "v7oso327T_wa"
   },
   "outputs": [],
   "source": [
    "doc_writer_agent = create_agent(\n",
    "    authoring_llm,\n",
    "    [write_document, edit_document, read_document],\n",
    "    (\"You are an expert writing customer assistance responses.\\n\"\n",
    "    \"Below are files currently in your directory:\\n{current_files}\"),\n",
    ")\n",
    "context_aware_doc_writer_agent = prelude | doc_writer_agent\n",
    "doc_writing_node = functools.partial(\n",
    "    agent_node, agent=context_aware_doc_writer_agent, name=\"DocWriter\"\n",
    ")\n",
    "\n",
    "note_taking_agent = create_agent(\n",
    "    authoring_llm,\n",
    "    [create_outline, read_document, reference_previous_responses],\n",
    "    (\"You are an expert senior researcher tasked with writing a customer assistance outline and\"\n",
    "    \" taking notes to craft a customer assistance response.\\n{current_files}\"),\n",
    ")\n",
    "context_aware_note_taking_agent = prelude | note_taking_agent\n",
    "note_taking_node = functools.partial(\n",
    "    agent_node, agent=context_aware_note_taking_agent, name=\"NoteTaker\"\n",
    ")\n",
    "\n",
    "copy_editor_agent = create_agent(\n",
    "    authoring_llm,\n",
    "    [write_document, edit_document, read_document],\n",
    "    (\"You are an expert copy editor who focuses on fixing grammar, spelling, and tone issues\\n\"\n",
    "    \"Below are files currently in your directory:\\n{current_files}\"),\n",
    ")\n",
    "context_aware_copy_editor_agent = prelude | copy_editor_agent\n",
    "copy_editing_node = functools.partial(\n",
    "    agent_node, agent=context_aware_copy_editor_agent, name=\"CopyEditor\"\n",
    ")\n",
    "\n",
    "authoring_supervisor_agent = create_team_supervisor(\n",
    "    authoring_llm,\n",
    "    (\"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers: {team_members}. You should always verify the technical\"\n",
    "    \" contents after any edits are made. \"\n",
    "    \"Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When each team is finished,\"\n",
    "    \" you must respond with FINISH.\"),\n",
    "    [\"DocWriter\", \"NoteTaker\", \"CopyEditor\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUiNMpJBGXN0"
   },
   "source": [
    "### Document Writing Team LangGraph Construction\n",
    "\n",
    "This part is almost exactly the same (with a few extra nodes) as our Research Team LangGraph construction - so we'll leave it as one block!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Q6n8A1ytxVTv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x161a4fd90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authoring_graph = StateGraph(DocWritingState)\n",
    "authoring_graph.add_node(\"DocWriter\", doc_writing_node)\n",
    "authoring_graph.add_node(\"NoteTaker\", note_taking_node)\n",
    "authoring_graph.add_node(\"CopyEditor\", copy_editing_node)\n",
    "authoring_graph.add_node(\"AuthoringSupervisor\", authoring_supervisor_agent)\n",
    "\n",
    "authoring_graph.add_edge(\"DocWriter\", \"AuthoringSupervisor\")\n",
    "authoring_graph.add_edge(\"NoteTaker\", \"AuthoringSupervisor\")\n",
    "authoring_graph.add_edge(\"CopyEditor\", \"AuthoringSupervisor\")\n",
    "\n",
    "authoring_graph.add_conditional_edges(\n",
    "    \"AuthoringSupervisor\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\n",
    "        \"DocWriter\": \"DocWriter\",\n",
    "        \"NoteTaker\": \"NoteTaker\",\n",
    "        \"CopyEditor\" : \"CopyEditor\",\n",
    "        \"FINISH\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "authoring_graph.set_entry_point(\"AuthoringSupervisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_authoring_graph = authoring_graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zx-EKGkHKUBO"
   },
   "source": [
    "#### Display Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x16158ead0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_authoring_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yB_rOw1hGpwd"
   },
   "source": [
    "Just as before - we'll need to create an \"interface\" between the level above, and our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "G-RbbCKoG_nt"
   },
   "outputs": [],
   "source": [
    "def enter_authoring_chain(message: str, members: List[str]):\n",
    "    results = {\n",
    "        \"messages\": [HumanMessage(content=message)],\n",
    "        \"team_members\": \", \".join(members),\n",
    "    }\n",
    "    return results\n",
    "\n",
    "authoring_chain = (\n",
    "    functools.partial(enter_authoring_chain, members=authoring_graph.nodes)\n",
    "    | compiled_authoring_graph\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgyhpTrRNgQd"
   },
   "source": [
    "Now we can test this out!\n",
    "\n",
    "> NOTE: It is possible you may see an error here - rerun the cell to clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWUxv4XDx3kg",
    "outputId": "62ee7d3d-31ba-4348-b852-7fd96f6875ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AuthoringSupervisor': {'next': 'DocWriter'}}\n",
      "---\n",
      "{'DocWriter': {'messages': [HumanMessage(content='Common use cases and domains where data is frequently applied include:\\n\\n1. **Healthcare**: Patient management, diagnostics, treatment predictions, and health monitoring.\\n2. **Finance**: Fraud detection, risk assessment, algorithmic trading, and customer insights.\\n3. **Retail**: Inventory management, personalized marketing, and sales forecasting.\\n4. **Transportation**: Route optimization, predictive maintenance, and fleet management.\\n5. **Manufacturing**: Supply chain optimization, quality control, and production scheduling.\\n6. **Customer Service**: Chatbots, sentiment analysis, and feedback management.\\n7. **Education**: Learning analytics, personalized learning experiences, and administrative efficiency.\\n8. **Marketing**: Audience segmentation, campaign tracking, and performance analysis.\\n\\nEach of these domains makes extensive use of data to improve processes, enhance decision-making, and drive innovations.', additional_kwargs={}, response_metadata={}, name='DocWriter')]}}\n",
      "---\n",
      "{'AuthoringSupervisor': {'next': 'NoteTaker'}}\n",
      "---\n",
      "{'NoteTaker': {'messages': [HumanMessage(content='I have created an outline for customer assistance that includes common use-cases and domains for data application. The outline has been saved as \"customer_assistance_outline.md\". If you need further information or a more detailed response based on this outline, please let me know!', additional_kwargs={}, response_metadata={}, name='NoteTaker')]}}\n",
      "---\n",
      "{'AuthoringSupervisor': {'next': 'CopyEditor'}}\n",
      "---\n",
      "{'CopyEditor': {'messages': [HumanMessage(content='I have edited the outline for customer assistance, ensuring clarity and coherence. The updated document has been saved successfully. If you need any further assistance or details, feel free to ask!', additional_kwargs={}, response_metadata={}, name='CopyEditor')]}}\n",
      "---\n",
      "{'AuthoringSupervisor': {'next': 'FINISH'}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for s in authoring_chain.stream(\n",
    "    \"What are the most common use-cases in this data. What are the most common domains?\",\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpW2R9SUHGUq"
   },
   "source": [
    "## Task 5: Meta-Supervisor and Full Graph\n",
    "\n",
    "Finally, now that we have our two LangGraph agents (some of which are already multi-agent), we can build a supervisor that sits above all of them!\n",
    "\n",
    "The final process, surprisingly, is quite straight forward!\n",
    "\n",
    "Let's jump in!\n",
    "\n",
    "First off - we'll need to create our supervisor agent node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "wkpxeUf9ygKp"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "super_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "super_supervisor_agent = create_team_supervisor(\n",
    "    super_llm,\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following teams: {team_members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When all workers are finished,\"\n",
    "    \" you must respond with FINISH.\",\n",
    "    [\"Research team\", \"Response team\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUvOh_xWIKig"
   },
   "source": [
    "We'll also create our new state - as well as some methods to help us navigate the new state and the subgraphs.\n",
    "\n",
    "> NOTE: We only pass the most recent message from the parent graph to the subgraph, and we only extract the most recent message from the subgraph to include in the state of the parent graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "O7HJ8MF0yh_i"
   },
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "def get_last_message(state: State) -> str:\n",
    "    return state[\"messages\"][-1].content\n",
    "\n",
    "def join_graph(response: dict):\n",
    "    return {\"messages\": [response[\"messages\"][-1]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5RHao1sIanG"
   },
   "source": [
    "Next, we'll create our base graph.\n",
    "\n",
    "Notice how each node we're adding is *AN ENTIRE LANGGRAPH AGENT* (wrapped into an LCEL chain with our helper functions above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "PfCWABCMIaFy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x16087b5c0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_graph = StateGraph(State)\n",
    "\n",
    "super_graph.add_node(\"Research team\", get_last_message | research_chain | join_graph)\n",
    "super_graph.add_node(\"Response team\", get_last_message | authoring_chain | join_graph)\n",
    "super_graph.add_node(\"SuperSupervisor\", super_supervisor_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpwpUXMtI62E"
   },
   "source": [
    "Next, we'll create our edges!\n",
    "\n",
    "This process is completely idenctical to what we've seen before - just addressing the LangGraph subgraph nodes instead of individual nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "tLtjRuUYI-fx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x16087b5c0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_graph.add_edge(\"Research team\", \"SuperSupervisor\")\n",
    "super_graph.add_edge(\"Response team\", \"SuperSupervisor\")\n",
    "super_graph.add_conditional_edges(\n",
    "    \"SuperSupervisor\",\n",
    "    lambda x: x[\"next\"],\n",
    "    {\n",
    "        \"Response team\": \"Response team\",\n",
    "        \"Research team\": \"Research team\",\n",
    "        \"FINISH\": END,\n",
    "    },\n",
    ")\n",
    "super_graph.set_entry_point(\"SuperSupervisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x1608e7ce0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_super_graph = super_graph.compile()\n",
    "compiled_super_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1KMfFqgJKw8"
   },
   "source": [
    "That's it!\n",
    "\n",
    "Now we can finally use our full agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3M6wUDR-yk8s",
    "outputId": "056fe89e-5a81-4852-f0cb-35367da8cef0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SuperSupervisor': {'next': 'Research team'}}\n",
      "---\n",
      "{'Research team': {'messages': [HumanMessage(content=\"### Report on the Rise of Context Engineering in the Large Language Model Space in 2025\\n\\n#### Introduction\\nIn 2025, context engineering has gained prominence in the realm of large language models (LLMs), signaling a paradigm shift in the way AI systems are designed to understand and engage with complex information. This report examines the evolution of context engineering, its integration into LLMs, and its impact on user interactions and organizational AI strategies.\\n\\n#### Understanding Context Engineering\\nContext engineering is the strategic design of an AI's informational setting to enhance its comprehension and responsiveness to intricate user queries. Unlike traditional prompt engineering, which centers on crafting precise inputs, context engineering encompasses the orchestration of ongoing contextual information, allowing models to prioritize relevant content while filtering out extraneous data. This development has become indispensable as LLMs evolve to manage extensive context windows, enabling richer interactions and deeper analysis of large texts.\\n\\n#### Key Developments in 2025\\n1. **Enhanced LLM Capabilities**: The architectural advancements in LLMs, especially in models like GPT-4 Turbo and Claude 4, have significantly expanded their capabilities. These models feature improved contextual memory and a better understanding of nuanced prompts, enabling them to maintain coherent and contextually aligned dialogues over extended interactions.\\n\\n2. **Integration of Agent-based Systems**: The introduction of agent-based architectures signifies a departure from conventional stateless models. By integrating persistent memory and advanced reasoning, AI agents can adapt and learn from each interaction, creating a more personalized experience for users. This approach ensures that conversations remain relevant and contextually rich, enhancing user satisfaction.\\n\\n3. **Operational Efficiency**: Organizations employing structured context engineering are realizing remarkable improvements in operational functions. Companies report faster implementation timelines and reduced costs, along with enhanced accuracy in AI outputs, achieving success rates that dwarf those of previous generations of AI systems.\\n\\n#### Impact on AI Usage in 2025\\nThe influence of context engineering transcends technical enhancements; it radically reshapes how users and businesses interact with AI:\\n\\n- **User Experience Enhancement**: As AI systems become adept at contextual understanding, users enjoy more fluid and personalized interactions. This advancement supports complex tasks and decision-making processes, thus optimizing productivity across various professional domains.\\n\\n- **Scalability of AI Solutions**: Context engineering facilitates greater scalability in AI applications, allowing businesses to deploy sophisticated solutions that address specific industry requirements dynamically. This capability enhances operational agility and the capacity to innovate.\\n\\n- **Broader Accessibility**: The advancements in context management led by context engineering have made it possible to develop on-device AI features, driving usage in consumer electronics while ensuring data privacy. Users now expect instant responses from their AI tools without compromising their security.\\n\\n#### Conclusion\\nIn 2025, context engineering stands as a transformative force within the domain of AI and LLMs. By fostering an environment where models not only retrieve but also intelligently manage contextual information, the potential for AI to enhance human decision-making and productivity is exponentially amplified. Organizations that integrate context engineering into their AI strategies will likely derive significant competitive advantages, driving innovation and effectiveness in a rapidly advancing technological landscape. As this field continues to evolve, context engineering will play a crucial role in shaping the future of intelligent systems across various sectors.\", additional_kwargs={}, response_metadata={}, name='HowPeopleUseAIRetriever')]}}\n",
      "---\n",
      "{'SuperSupervisor': {'next': 'Response team'}}\n",
      "---\n",
      "{'Response team': {'messages': [HumanMessage(content='I have successfully edited both the **Context_Engineering_Report_2025.txt** and **Context_Engineering_Outline_2025.txt** files for grammar, spelling, and tone issues. If you need any further modifications or additional documents, feel free to ask!', additional_kwargs={}, response_metadata={}, name='CopyEditor')]}}\n",
      "---\n",
      "{'SuperSupervisor': {'next': 'FINISH'}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "WORKING_DIRECTORY = Path(create_random_subdirectory())\n",
    "\n",
    "for s in compiled_super_graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Write a report on the rise of context engineering in the LLM Space in 2025, and how it's impacting how people are using AI.\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    {\"recursion_limit\": 30},\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuZAvSlJJpPP"
   },
   "source": [
    "## SAMPLE POST!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOEMCrXTJaxW"
   },
   "source": [
    "### Report on the Rise of Context Engineering in the LLM Space in 2025\n",
    "\n",
    "#### Introduction\n",
    "As we move further into 2025, the landscape of artificial intelligence continues to evolve, particularly in the domain of large language models (LLMs). One significant trend emerging is \"context engineering,\" which has begun to outpace the earlier focus on prompt engineering. This report explores how context engineering is reshaping the dynamics of AI usage, enhancing the capabilities of LLMs to perform complex tasks, and ultimately influencing the way users interact with AI technologies.\n",
    "\n",
    "#### The Emergence of Context Engineering\n",
    "In previous years, prompt engineering involved crafting inputs to guide LLMs to generate desired outputs. However, by 2025, the limitations of traditional prompt engineering have become evident, especially as applications require more dynamic interactions and multi-turn dialogues. Context engineering has emerged as a new paradigm, prioritizing the construction of strategies and systems that enable LLMs to access and utilize extensive contextual information effectively.\n",
    "\n",
    "Modern LLMs, such as GPT-4 Turbo and Claude 3, now boast context windows that can handle up to 1 million tokens. This substantial increase allows these models to grasp more extensive content, such as books or lengthy documents, fundamentally changing what they can achieve in real-world applications.\n",
    "\n",
    "#### Key Developments in Context Engineering\n",
    "1. **Dynamic Knowledge Management**: The shift towards context engineering facilitates more sophisticated knowledge management within AI systems. These systems now use persistent memory and adaptive reasoning, enabling them to maintain context across interactions. For example, agent-based LLMs can now engage in workflows requiring multiple exchanges, which is vital for complex applications requiring follow-ups and extended dialogues.\n",
    "\n",
    "2. **Improved Context Lengths**: Advances in transformer architectures have led to the possibility of extending native context lengths dramatically. As a result, LLMs can process larger datasets directly, enhancing their capacity to deliver accurate and relevant outputs without extensive re-prompting.\n",
    "\n",
    "3. **Context Compression and Retrieval**: Techniques such as context compression, where information is stored externally or synthesized to maximize relevance, are gaining traction. Methods identified in recent studies highlight the importance of integrating efficient retrieval systems and summarization techniques to make the most of the available context.\n",
    "\n",
    "4. **The Rise of Multi-Agent Systems**: In 2025, LLM applications are increasingly shifting towards multi-agent architectures, where different AI agents work collaboratively, leveraging various tools and pieces of information to improve output accuracy and reduce operational inefficiencies.\n",
    "\n",
    "#### Impact on AI Usage\n",
    "The implications of context engineering are far-reaching and transformative for users and organizations:\n",
    "\n",
    "- **Enhanced Accuracy**: Enterprises adopting context engineering report accuracy rates of 90-95%, a significant improvement over the 65-75% typically associated with earlier methods. This rise in performance is generating more trust in AI systems across various sectors.\n",
    "\n",
    "- **Faster Deployment and Cost Efficiency**: Organizations employing structured context engineering have demonstrated a 3x increase in the speed of bringing AI solutions to production and a 40% reduction in operational costs compared to traditional prompt-based methodologies.\n",
    "\n",
    "- **Adaptability and Scalability**: Context-engineered systems are inherently more adaptable, allowing businesses to scale AI applications rapidly in response to evolving needs without overhauling the underlying architecture.\n",
    "\n",
    "- **Augmentation of Human Intelligence**: As context engineering allows AI systems to interact in more meaningful ways, they are increasingly positioned as partners in decision-making processes, rather than mere tools. This evolution enhances the collaborative potential between humans and AI.\n",
    "\n",
    "#### Conclusion\n",
    "The rise of context engineering marks a critical turning point in the development and application of LLMs. As AI systems become increasingly capable of managing and utilizing complex contextual information, they are set to enhance user experiences, improve efficiency, and drive new innovations across industries. Organizations that embrace this trend will likely lead the charge into a future where AI is not just a tool for automation but a collaborative partner in problem-solving and creativity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
